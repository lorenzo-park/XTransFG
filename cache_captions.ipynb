{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0ef5dddf3396bdd55ac5e0a59d6dc121e77b0322ce4c768edc846bd1ea0f25d09",
   "display_name": "Python 3.7.10 64-bit ('xfg': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 202/202 [00:00<00:00, 401.44it/s]\n",
      "100%|██████████| 11788/11788 [01:35<00:00, 123.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./pretrained/roberta')\n",
    "model = RobertaForMaskedLM.from_pretrained('./pretrained/roberta', output_hidden_states=True)\n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "txt_root = \"./data/text_c10\"\n",
    "img_root = \"./data/CUB_200_2011/images\"\n",
    "sentences = []\n",
    "sentence_lengths = []\n",
    "saved_paths = []\n",
    "for bird in tqdm.tqdm(os.listdir(txt_root)):\n",
    "    if \".txt\" in bird:\n",
    "        continue\n",
    "    bird_root = os.path.join(txt_root, bird)\n",
    "    for filename in os.listdir(bird_root):\n",
    "        if \".txt\" not in filename:\n",
    "            continue\n",
    "        with open(os.path.join(bird_root, filename)) as f:\n",
    "            lines = []\n",
    "            lengths = []\n",
    "            for line in f.readlines():\n",
    "                lines.append(line)\n",
    "                line = list(filter(lambda x: len(x)!=1, line.split(\" \")))\n",
    "                lengths.append(len(line))\n",
    "            input_txt = lines[lengths.index(sorted(lengths)[-3])]\n",
    "            # input_txt = f.readlines()[0]\n",
    "            sentences.append(input_txt)\n",
    "            sentence_lengths.append(len(input_txt))\n",
    "            saved_path = os.path.join(img_root, bird, filename) + \".npy\"\n",
    "            saved_paths.append(saved_path)\n",
    "tokens = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(\"cuda:0\")\n",
    "\n",
    "tokens_lengths = []\n",
    "for saved_path, input_id, mask in tqdm.tqdm(zip(saved_paths, tokens.input_ids, tokens.attention_mask), total=len(saved_paths)):\n",
    "    input_id = input_id.unsqueeze(0)\n",
    "    mask = mask.unsqueeze(0)\n",
    "    outputs = model.roberta(input_id, attention_mask=mask)\n",
    "    tokens_lengths.append(outputs.hidden_states[-1].shape[1])\n",
    "    try:\n",
    "        os.remove(saved_path.replace(\".npy\", \".pt\"))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    hidden_state = (outputs.hidden_states[-1] + outputs.hidden_states[-2] + outputs.hidden_states[-3] + outputs.hidden_states[-4]) / 4\n",
    "\n",
    "    np.save(saved_path, hidden_state.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(outputs.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 49, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "outputs.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}