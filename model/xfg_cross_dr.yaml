# @package _global_
model: xfg_cross_dr
transformer:
  attention_dropout_rate: 0.0

encoder:
  dropout: 0.1
  hidden_size: 768
  transformer:
    mlp_dim: 3072
    num_heads: 12
    num_layers: 1
    attention_dropout_rate: 0.0

decoder:
  dropout: 0.1
  hidden_size: 768
  transformer:
    mlp_dim: 3072
    num_heads: 12
    num_layers: 1
    attention_dropout_rate: 0.0